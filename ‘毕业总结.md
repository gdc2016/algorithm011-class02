# ‘毕业总结

通过十周的算法学习，主要学习了以下数据结构和算法方面的知识。

### 数组

在python一般采用列表来表示数组。

```python
#可以定义一个空数组
array = []
#也可以定义一个有初始值的数组
array = [1,2,3,4]
```

定义数组的过程中计算机会为数组开辟一段连续的使用空间，数组的常用操作如下：

- 查询：通过数组的索引查找相应的元素，时间复杂度为O(1)
- 末尾添加：在数组末尾添加元素，时间复杂度为O(1)
- 插入：在数组的特定位置插入一个值，对于长度为n的数组，在第i个位置上插入一个值会导致n-i+1的值向后移动，故时间复杂度为O(n)
- 删除：在数组中删除一个值，对于长度为n的数组，在第i个位置上删除一个值会导致n-i的值向前移动，故时间复杂度为O(n)
- 修改：修改对应索引下元素的值，时间复杂度为O(1)
- 遍历：顺序或倒序访问数组中每一个元素，时间复杂度为O(n)

### 链表

链表的主要类型如下：

![image-20200626233743188.jpg](../../../../个人学习/算法训练营/homework/algorithm011-class02/Week_01/image-20200626233743188.jpg)

在python中链表的节点实现方式如下：

```python
#单链表节点
class Node():
    def __init__(self,value):
        self.val = value
        self.next = None
#双链表节点
class Node():
    def __init__(self,value):
        self.val = value
        self.prev = None
        self.next = None
```

链表的节点通过next指针进行连接，因此和数组不同，链表在计算机中分配的内存空间可以不连续。

链表的常用操作如下：

- 查询：由于链表并不像数组中每个元素都存在索引，所以链表的查询只能通过循环遍历从head位置移动到需要访问的节点，故时间复杂度为O(n)
- 插入：在链表中插入一个节点，除去查询插入位置的操作外，就插入这个动作本身，只需修改当前位置后一个指针和插入节点后一个指针的指向即可，不会引起链表节点的群移，故时间复杂度为O(1)
- 删除：在链表中删除一个节点，除去查询删除节点位置的操作外，就删除节点操作本身，只需修改前一个节点的next指针以级删除节点的next指针将这个节点移出链表即可，不会引起链表节点的群移，故时间复杂度为O(1)
- 从前添加：在链表的头部添加一个节点，只需将添加节点的next指向链表的第一个节点，在将head指向新加的节点即可，不会引起链表节点的群移，故时间复杂度为O(1)
- 从后添加：在链表的尾部添加一个元素，在事先记录下当前尾部的情况下，只需将尾部节点的next指向新加的节点，将尾指针指向新增节点即可，不会引起链表节点的群移，故时间复杂度为O(1)

### 跳表

跳表的示意图如下：

![skip-list.jpg](../../../../个人学习/算法训练营/homework/algorithm011-class02/Week_01/skip-list.jpg)



由于在查询链表时需要从头进行遍历，对于一个比较长的有序链表，O(N)时间复杂度的查询就显得比较慢。为了提升有序链表的查询，采取升维的方式，上一个维度的移动步长是下一个维度的两倍，故而产生了跳表这个数据结构。

跳表的优势在于原理简单、容易实现、方便扩展、效率更高，但是前提是每个元素必须排列有序。

跳表的常用操作如下：

- 查询：在跳表中查询一个节点的值，先在高维度的位置快速移动到该节点附近的位置，之后再下维度寻找，直到最终找到为止。由于上一个维度的移动步长是下一个维度的两倍，所以时间复杂度为O(log(n))
- 添加：在跳表中新增一个节点，新增一个节点后，为了保持跳表的查询效率，需要在插入数据的时候，索引节点也需要相应的增加、或者重建索引，来避免查找效率的退化。由于上一个维度的移动步长是下一个维度的两倍，故整个添加过程的时间复杂度为O(log(n))
- 删除：跳表删除数据时，要把索引中对应节点也要删掉，由于上一个维度的移动步长是下一个维度的两倍，故整个删除过程的时间复杂度为O(log(n))

### 栈

栈的示意图如下：

![image-20200627124140447.jpg](../../../../个人学习/算法训练营/homework/algorithm011-class02/Week_01/image-20200627124140447.jpg)

栈的常用操作如下：

- 判断栈是否为空：时间复杂度为O(1)
- 入栈：将元素从栈顶放入，时间复杂度为O(1)
- 出栈：若栈不为空，将栈顶元素出栈，时间复杂度为O(1)
- 查询栈顶元素：若栈不为空，查找当前栈顶元素的值，不改变栈内当前元素，时间复杂度为O(1)

从栈的操作可知，栈的特性为后入先出（LIFO)

### 队列

队列的示意图如下：

![image-20200627002822266.jpg](../../../../个人学习/算法训练营/homework/algorithm011-class02/Week_01/image-20200627002822266.jpg)

与栈不同，队列的特性是先入先出(FIFO)。

队列的常用操作如下：

- 判断队列是否为空：时间复杂度为O(1)
- 入队：从队列尾部将元素放入队列，时间复杂度为O(1)
- 出队：队首元素从队列的头部移出队列，时间复杂度为O(1)
- 查询队尾元素：查询当前队尾元素的值，时间复杂度为O(1)
- 查询队首元素：查询当前队首元素的值，时间复杂度为O(1)

队列主要分为顺序队列，双端队列和循环队列

### 哈希表和集合

哈希表，也是散列表，与数组通过索引不同，哈希表是通过键值key对元素进行直接访问。哈希函数的常见构造方式有：

1. 直接定制法
2. 数字分析法
3. 平方取中法
4. 折叠法
5. 除留余数法

集合（set）是一个元素不重合并且无序的数据结构，与哈希表不同，集合不存在键值key索引。

### 树，二叉树，二叉搜索树

树与二叉树的区别是二叉树只有左子树与右子树，但是树可以有多个子树。

二叉树的遍历方式有四种：

1. 前序遍历：又称先序遍历，先访问根结点再访问左子树和右子树
2. 中序遍历：先访问左子树，再访问根节点最后再访问右子树
3. 后续遍历：先访问左子树，再访问右子树最后访问根
4. 层序遍历：依次访问每层的结点

### 堆

通过堆可以找到序列中的最大值（大根堆）或最小值（小根堆）的数据结构

对于大根堆，常用的操作有：

1. 找到当前最大值：直接获取首项元素，时间复杂度为O(1)
2. 删除元素：由于添加元素回导致元素的调整，时间复杂度为O(logn)
3. 添加元素：如当前位置就是该元素的最佳位置，时间复杂度为O(1)，不然会出现位置的调整，时间复杂度为O(logn)

二叉堆的主要性质如下：

1. 是一棵完全二叉树
2. 树中任意结点的值总是大于等于其子节点的值

二叉堆一般以数组的方式实现：

1. 索引为i的左孩子结点时2i+1
2. 索引为i的右孩子结点时2i+2
3. 索引为i的父节点的索引是(i-1)/2

二叉堆也是优先队列的常用实现方式。

### 图

图的组成部分：

- 点
  1. 度：可以与该点连通的边的个数，在有向图中分入度和出度
  2. 判断点与点之间是否连通
- 边
  1. 方向（分有向和无向）
  2. 权重

图的种类主要有：

1. 有向图

   有向无权图

   有向有权图

2. 无向图

   无向无权图

   无向有全图

图的算法主要有：

1. 广度优先搜索

   基本思想是：首先访问起始顶点v，然后由v出发，依次访问v的各个未被访问过的邻接顶点，然后再依次访问这些顶点的所有未被访问过的邻接顶点，再从这些访问过的顶点出发，再访问它们所有未被访问过的邻接顶点….以此类推，直到途中所有的顶点都被访问过为止。类似于二叉树的层序遍历

2. 深度优先搜索：

   采用回溯的思想，从图的起始顶点出发，向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，直到最终遍历完整个图。

3. 拓扑排序

4. 最短路径算法

### 泛型递归

递归是通过函数体来进行循环，在汇编语言中并没有所谓的循环，而是通过返回之前的代码或函数体达到循环的效果，也就是递归。

递归学习要点：

1. 初学时可以通过画树形图理解递归思想
2. 熟练后要抛弃人肉递归
3. 分析问题时尝试将其拆解成可重复解决的问题
4. 利用数学归纳法的思维

### 分治和回溯

分治（Divide & Conquer) 的基本思想是将一个大问题分解为若干个规模较小的子问题，这些子问题相互独立且与原问题性质相同，分别求出这些子问题的解后，再通过合适的方法将他们合并成整个问题的解。分治和递归的区别在于递归未必存在将子问题合并求解的过程，可能递归完后就直接求解。

回溯：采用试错的思想，它尝试分步的去解决一个问题，首先尝试从一个方向来解答问题，当发现该方向无法得到正确的结果时，便进行回退，从其它的方向来寻求解答，深度优先搜索采用的便是回溯的思想。

### 贪心算法

贪心算法的基本思想是从局部分析问题，每次找到一个局部中的最优情况，不断叠加，从而找到整个问题的最优解。

与动态规划不同，贪心算法对每个子问题的解决方法都做出选择，不能回退。动态规划会保存之前子问题的解，并根据以前的结果对当前进行选择，可以回退。

贪心算法存在一定的局限性，因为并不是每个局部都找最优解叠加就一定是整个问题的最优解，故只有在一些特定场景下可以采用贪心算法。

如最优化问题，图中的最小生成树和哈夫曼编码。

一旦一个问题可以通过贪心算法来解决，那贪心算法一定是该问题的最优解。

由于贪心法的高效性以及其所求得的答案比较接近最优结果，故在现实场景中贪心法也可以用作辅助算法或者直接解决一些要求结果不特别精确的问题。

### 二分查找

对一个数组的查找方式可以通过从头或从尾遍历每个元素，从而找到符合条件的元素，这样的话每个元素都需访问一次，时间复杂度为O(n)，对于很长的数组，这样的查询方式效率就显得偏低了。针对有序数组，可以采用二分查找的方式提升查找效率，由于每次的对半查找，故时间复杂度为O(logn)，相比遍历查找大幅提升了。

二分查找的代码模板如下：

```python
left, right = 0, len(array) - 1
while left <= right:
    mid = (left + right) / 2
    if array[mid] == target:
    	# find the target!!
        break or return result
    elif array[mid] < target:
        left = mid + 1
    else:
        right = mid - 1
```

### 动态规划

动态规划的思想和递归和分治没有本质上的区别，和递归和分治的相同点是：

**通过寻找重复子问题从而找到问题的解**

与递归和分治不同的是：

**满足最优子结构，中途淘汰次优解，避免重复计算**

动态规划的解题关键点如下：

1. 最优子结构 opt[n] = best_of(opt[n-1], opt[n-2], …)
2. 储存中间状态：opt[i]
3. 递推公式（美其名曰：状态转移方程或者 DP 方程）

示例：

斐波那契问题：

从该问题中可以得到的最优子结构是：

F(n) = F(n-1)+F(n-2)

以此，可以得到递推公式为：

dp(n) = dp(n-1)+dp(n-2)

最后就是结合下面的穷举框架和递推方程求出问题的解了：

```python
for 状态1 in 状态1的所有取值：
    for 状态2 in 状态2的所有取值：
        for ...
            dp[状态1][状态2][...] = 择优(选择1，选择2...)

```

### 字典树

字典树，即 Trie 树，又称单词查找树或键树，是一种树形结构。典型应用是用于统计和排序大量的字符串。

它的优点是：最大限度地减少无谓的字符串比较，查询效率比哈希表高。

### 并查集

并查集的代码实现如下：

```python
# Python 
def init(p): 
	# for i = 0 .. n: p[i] = i; 
	p = [i for i in range(n)] 
 
def union(self, p, i, j): 
	p1 = self.parent(p, i) 
	p2 = self.parent(p, j) 
	p[p1] = p2 
 
def parent(self, p, i): 
	root = i 
	while p[root] != root: 
		root = p[root] 
	while p[i] != i: # 路径压缩 ?
		x = i; i = p[i]; p[x] = root 
	return root
```

### 位运算

十进制转换为二进制的方法：

将十进制数不断除以2并从末尾往前填写每次除下来的余数，等到整个除完后就能得到二进制数

常用的位运算符如下：

按位或：|

按位与：&

按位取反：~

按位异或：^

常用的位运算：

1. 将 x 最右边的 n 位清零： x& (~0 << n)
2. 获取 x 的第 n 位值（ 0 或者 1）： (x >> n) & 1
3. 获取 x 的第 n 位的幂值： x& (1 << n)
4. 仅将第 n 位置为 1：x | (1 << n)
5. 仅将第 n 位置为 0：x & (~ (1 << n))
6. 将 x 最高位至第 n 位（含）清零： x& ((1 << n) -1）
7. 将第 n 位至第 0 位（含）清零： x& (~ ((1 << (n + 1))-1))

实战运算要点（常用的一些操作转换为位运算）

- 判断奇偶：
- 判断偶数：
- x%2==0 --> x&1 == 0
- 判断奇数：
- x%2==1 --> x&1 == 1
- 将变量除以2：
- x/2 --> x>>1
- 清零最低位的 1:
- X = X&(X-1)
- 得到最低位的 1:
- X&-X
- X&~X => 0

### 布隆过滤器：

布隆过滤器可以用于检索一个元素是否在一个集合中。

优点是空间效率和查询时间都远远超过一般的算法。

缺点是有一定的误识别率和删除困难。
应用场景：

1. 比特币网络
2. 分布式系统（Map-Reduce） — Hadoop、search engine
3. Redis 缓存
4. 垃圾邮件、评论等的过滤

### LRU缓存

两个要素： 大小 、替换策略
Hash Table + Double LinkedList

操作时间复杂度：

- O(1) 查询
- O(1) 修改、更新

### 排序算法

常见排序算法：

1. 冒泡排序
2. 选择排序
3. 插入排序
4. 归并排序
5. 快速排序
6. 堆排序

### 字符串

1. Atoi
2. 字符串暴力匹配
3. Rabin-Karp
4. KMP算法

### 自我总结

经过算法训练营的学习首先让我了解了一些算法自我学习的方法，比如题目不要只做一遍，不要死磕题目，没思路就拥抱题解，通过五毒神掌的方式理解掌握解题方法。这些都让我意识到了自己以前学习数据结构和算法的误区。通过思维导图建立整个数据结构和算法的知识体系，收集整理各类数据结构和算法的解题思路和解题模板，需要进一步熟练掌握。

经过了10周的学习，通过视频的学习和习题的训练，相比以前对于数据结构和算法的茫然、不知所措、不得其法，至少现在不再向以前那样畏惧做题，遇到题目就完全没有思路了，可以尝试切题并通过相关算法思路尝试解决，并且不再执着死磕，积极学习网上的高票代码，学习别人优秀的代码，不再像以前做完题就了事。

虽然现在毕业了，但是通过期中和期末考试也让我看到了自己的不足，之后我还是会坚持在算法训练营学到的技能和学习方法进一步的刷题，总结，真正掌握算法和数据结构，提升自己的编程内功，更好的将编程运用到日常工作和生活中去。